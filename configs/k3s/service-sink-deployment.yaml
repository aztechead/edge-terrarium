# =============================================================================
# KUBERNETES DEPLOYMENT - SERVICE SINK
# =============================================================================
# This deployment manages the Service Sink application, which handles all
# HTTP requests that don't match the Custom client routing patterns.
#
# The Service Sink is a simple C application that processes requests and
# returns JSON responses with path analysis information.
#
# Key Concepts:
# - Deployment: Manages Pod replicas and rolling updates
# - Pod: The smallest deployable unit in Kubernetes (one or more containers)
# - ReplicaSet: Ensures a specified number of Pod replicas are running
# - Service: Provides network access to Pods
# - Health Probes: Monitor container health and restart if needed
#
# Impact:
# - Runs the service-sink application in Kubernetes
# - Handles default routing for all non-Custom client requests
# - Provides health checks for automatic recovery
# - Uses single replica to prevent conflicts
# - Processes requests and logs them to logthon
#
# Documentation: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
# =============================================================================

apiVersion: apps/v1                # Apps API version for Deployment resources
kind: Deployment                   # Resource type - creates a deployment
metadata:                          # Metadata about this deployment
  name: service-sink               # Name of the deployment
  namespace: edge-terrarium        # Namespace where this resource lives
  labels:                          # Labels for organizing resources
    app: service-sink              # Identifies this as the service-sink app
    component: backend             # Identifies this as a backend component

spec:                              # Specification of the deployment
  replicas: 1                      # Number of Pod replicas to maintain (single instance for development)
  
  # Deployment strategy - use Recreate to ensure only one pod at a time
  # This prevents multiple instances from running simultaneously
  strategy:
    type: Recreate                 # Terminate old pods before creating new ones
  
  # Selector tells the deployment which Pods it manages
  selector:
    matchLabels:                   # Pods with these labels are managed by this deployment
      app: service-sink            # Must match the labels in the Pod template below

  # Template defines how new Pods should be created
  template:
    metadata:                      # Metadata for Pods created from this template
      labels:                      # Labels applied to each Pod
        app: service-sink          # Must match the selector above
        component: backend         # Identifies this as a backend component

    spec:                          # Specification for Pods created from this template
      # Init container to wait for logthon to be ready
      # This ensures service-sink can send logs to logthon on startup
      initContainers:
      - name: wait-for-logthon        # Name of the init container
        image: curlimages/curl:latest  # Lightweight curl image for health checks
        command: ['sh', '-c']          # Command to run
        args:                          # Arguments for the command
        - |                            # Multi-line script
          echo "Waiting for logthon service to be ready..."
          
          # Wait for logthon service to be ready
          # This ensures service-sink can send logs to logthon on startup
          RETRY_COUNT=0
          MAX_RETRIES=60  # 2 minutes max wait time
          until curl -s http://logthon-ingress-service.edge-terrarium.svc.cluster.local:5000/health > /dev/null; do
            RETRY_COUNT=$((RETRY_COUNT + 1))
            if [ $RETRY_COUNT -gt $MAX_RETRIES ]; then
              echo "ERROR: Timeout waiting for logthon service after $MAX_RETRIES attempts"
              echo "This indicates logthon failed to start or is taking too long"
              exit 1
            fi
            echo "Logthon service not ready yet (attempt $RETRY_COUNT/$MAX_RETRIES). Waiting..."
            sleep 2
          done
          echo "Logthon service is ready! Service-sink can start."
        resources:                     # Resource requirements for init container
          requests:                    # Minimum resources required
            memory: "32Mi"             # 32 MB of memory
            cpu: "50m"                 # 50 millicores of CPU
          limits:                      # Maximum resources allowed
            memory: "64Mi"             # 64 MB of memory
            cpu: "100m"                # 100 millicores of CPU
      
      containers:                  # List of containers in each Pod
      - name: service-sink         # Name of the container
        image: edge-terrarium-service-sink:latest  # Docker image to use
        imagePullPolicy: Never     # Never pull from registry (use local image for development)
        
        # Ports exposed by the container
        ports:
        - containerPort: 8080      # Port the container listens on
          name: http               # Name for referencing this port
          protocol: TCP            # Protocol (TCP or UDP)
        
        # Environment variables passed to the container
        env:
        - name: SERVICE_NAME       # Environment variable name
          value: "service-sink"    # Environment variable value
        - name: CONTAINER_NAME     # Container name for logging
          valueFrom:
            fieldRef:
              fieldPath: metadata.name  # Use pod name as container name
        - name: POD_NAME           # Pod name for logging
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: LOG_LEVEL          # Logging level
          value: "info"            # Set to info level
        - name: LOGTHON_HOST       # Logthon service hostname for log aggregation
          value: "logthon-ingress-service.edge-terrarium.svc.cluster.local"
        - name: LOGTHON_PORT       # Logthon service port
          value: "5000"
        
        # Resource requirements and limits
        resources:
          requests:                # Minimum resources required
            memory: "64Mi"         # 64 megabytes of memory
            cpu: "50m"             # 50 millicores of CPU (0.05 cores)
          limits:                  # Maximum resources allowed
            memory: "128Mi"        # 128 megabytes of memory
            cpu: "100m"            # 100 millicores of CPU (0.1 cores)
        
        # Liveness probe - checks if container is alive
        livenessProbe:
          httpGet:                 # HTTP GET request to check health
            path: /health          # Health check endpoint
            port: 8080             # Port to check
            httpHeaders:           # Custom headers to identify probe type
            - name: X-Probe-Type
              value: "liveness"
          initialDelaySeconds: 30  # Wait 30 seconds before first check
          periodSeconds: 30        # Check every 30 seconds (industry standard)
          timeoutSeconds: 5        # Wait 5 seconds for response
          failureThreshold: 3      # Mark unhealthy after 3 failures
        
        # Readiness probe - checks if container is ready to serve traffic
        readinessProbe:
          httpGet:                 # HTTP GET request to check readiness
            path: /health          # Health check endpoint
            port: 8080             # Port to check
            httpHeaders:           # Custom headers to identify probe type
            - name: X-Probe-Type
              value: "readiness"
          initialDelaySeconds: 5   # Wait 5 seconds before first check
          periodSeconds: 10        # Check every 10 seconds (industry standard)
          timeoutSeconds: 3        # Wait 3 seconds for response
          failureThreshold: 3      # Mark not ready after 3 failures

      # Restart policy for containers in the Pod
      restartPolicy: Always        # Always restart containers if they fail
